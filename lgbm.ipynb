{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=pd.errors.PerformanceWarning)\n",
    "import os\n",
    "\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "import catboost as cbt\n",
    "\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.metrics import mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to generates lag feature\n",
    "def add_lagged_features(df, cols, shifts=1, add_first=True):\n",
    "    for col in cols:\n",
    "        grouped_vals = df[[\"stock_id\", \"date_id\", col]].groupby([\"stock_id\",\"date_id\"])\n",
    "        fill_value = df[col].mean()\n",
    "        for shift in np.arange(shifts):\n",
    "            df[col+\"_shift\"+str(shift+1)] = grouped_vals.shift(shift+1).fillna(fill_value)\n",
    "        if add_first:\n",
    "            df = df.merge(grouped_vals.first().reset_index(), on=[\"date_id\",\"stock_id\"], suffixes=[\"\",\"_first\"])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main function to generate all features\n",
    "def generate_feature(df):         \n",
    "    df = add_lagged_features(df, [\"imbalance_ratio\",\"imbalance_indicator\",\"reference_price\",\"wap\", \"bid-ask_spread_indicator\", \"bid_size\", \"ask_size\"], shifts=5, add_first=True)\n",
    "    features = [c for c in df.columns if c not in [\"row_id\", \"time_id\", \"date_id\"]]\n",
    "    return df[features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing dataframe and split into X, Y\n",
    "def preprocess(df):\n",
    "    df = generate_feature(df)\n",
    "    df = df.dropna()\n",
    "    y = df[\"target\"]\n",
    "    df = df.drop(columns=[\"target\"])\n",
    "    x = df\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input dataframe\n",
    "df = pd.read_csv('../input/optiver-trading-at-the-close/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross validation\n",
    "df.set_index(\"date_id\", inplace=True)\n",
    "days  = np.sort(df.index.unique())\n",
    "tscv = TimeSeriesSplit(5)\n",
    "for fold, (train_index, val_index) in enumerate(tscv.split(days)):\n",
    "    if fold != 4:\n",
    "        continue\n",
    "    train_days, test_days = days[train_index], days[val_index]\n",
    "    train_df, val_df = df.loc[train_days], df.loc[test_days]\n",
    "    \n",
    "    print(f\"Train size: {len(train_df)} Train percentage: {len(train_df)/len(df)}\")\n",
    "    print(f\"Val size: {len(val_df)} Val percentage:{len(val_df)/len(df)}\")\n",
    "    print(f\"Total size: {(len(train_df) + len(val_df))} Total percentage: {(len(train_df)+ len(val_df)) / len(df)}\")\n",
    "    \n",
    "    train_df.reset_index(inplace=True)\n",
    "    val_df.reset_index(inplace=True)\n",
    "    \n",
    "    train_x, train_y = preprocess(train_df)\n",
    "    val_x, val_y = preprocess(val_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and validation dataset split\n",
    "train_df = df[df[\"date_id\"]<335].copy()\n",
    "val_df = df[df[\"date_id\"]>=335].copy()\n",
    "\n",
    "print(f\"Train size: {len(train_df)} Train percentage: {len(train_df)/len(df)}\")\n",
    "print(f\"Val size: {len(val_df)} Val percentage:{len(val_df)/len(df)}\")\n",
    "print(f\"Total size: {(len(train_df) + len(val_df))} Total percentage: {(len(train_df)+ len(val_df)) / len(df)}\")\n",
    "    \n",
    "train_x, train_y = preprocess(train_df)\n",
    "val_x, val_y = preprocess(val_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LGBM model\n",
    "lgbm_model = lgb.LGBMRegressor(objective='regression_l1', n_estimators=500)\n",
    "lgbm_model.fit(train_x, train_y, eval_set=[(val_x, val_y)], verbose=10, early_stopping_rounds=100)\n",
    "print(lgbm_model.best_score_)\n",
    "models.append(lgbm_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Catboost model\n",
    "cbt_model = cbt.CatBoostRegressor(objective='MAE', iterations=3000)\n",
    "cbt_model.fit(train_x, train_y, eval_set=[(val_x, val_y)], early_stopping_rounds=100, verbose=10)\n",
    "models.append(cbt_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Submit\n",
    "import optiver2023\n",
    "env = optiver2023.make_env()\n",
    "iter_test = env.iter_test()\n",
    "counter = 0\n",
    "for (test, revealed_targets, sample_prediction) in iter_test:\n",
    "    test = test.drop(columns=[\"currently_scored\"])\n",
    "    test = generate_feature(test)\n",
    "    sample_prediction['target'] = np.mean([model.predict(test) for model in models], 0)\n",
    "    env.predict(sample_prediction)\n",
    "    counter += 1"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
